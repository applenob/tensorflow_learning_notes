{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多GPU操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "记录tensorflow多GPU操作的各个方面。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Tensorflow中指定使用设备\n",
    "\n",
    "- \"/cpu:0\": 机器中的 CPU\n",
    "- \"/gpu:0\": 机器中的 GPU, 如果你有一个的话.\n",
    "- \"/gpu:1\": 机器中的第二个 GPU, 以此类推..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n"
     ]
    }
   ],
   "source": [
    "# 新建一个 graph.\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# 新建session with log_device_placement并设置为True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# 运行这个 op.\n",
    "print sess.run(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notebook里没有看到设备指派的log\n",
    "\n",
    "观察到一个问题，显存被全部占满。\n",
    "\n",
    "![图一](https://raw.githubusercontent.com/applenob/deep_learning_note/master/res/1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n"
     ]
    }
   ],
   "source": [
    "# 新建一个graph.\n",
    "with tf.device('/cpu:0'):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# 新建session with log_device_placement并设置为True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# 运行这个op.\n",
    "print sess.run(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然计算的时候指定了设备，但是问题来了，显存还是都被占满。\n",
    "\n",
    "![图二](https://raw.githubusercontent.com/applenob/deep_learning_note/master/res/2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 指定多个GPU\n",
    "# 新建一个 graph.\n",
    "c = []\n",
    "for d in ['/gpu:0', '/gpu:1']:\n",
    "    with tf.device(d):\n",
    "        a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3])\n",
    "        b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2])\n",
    "        c.append(tf.matmul(a, b))\n",
    "    with tf.device('/cpu:0'):\n",
    "        sum = tf.add_n(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 新建session with log_device_placement并设置为True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# 运行这个op.\n",
    "print sess.run(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![图三](https://raw.githubusercontent.com/applenob/deep_learning_note/master/res/3.jpg)\n",
    "\n",
    "**结论**：修改device不会改变显存占用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不全部占满显存的方法\n",
    "\n",
    "### 1.所有显存设置分配比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  44.   56.]\n",
      " [  98.  128.]]\n"
     ]
    }
   ],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)  \n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "print sess.run(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![图四](https://raw.githubusercontent.com/applenob/deep_learning_note/master/res/4.jpg)\n",
    "\n",
    "显示占用了所有显存的30%。\n",
    "\n",
    "### 2.自动增长：按需求分配显存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  44.   56.]\n",
      " [  98.  128.]]\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True  \n",
    "sess = tf.Session(config=config)  \n",
    "print sess.run(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![图五](https://raw.githubusercontent.com/applenob/deep_learning_note/master/res/5.jpg)\n",
    "\n",
    "上面的几种方法都是所有的gpu都会涉及，不够干脆。和别人共用GPU还是使用下面的方法。\n",
    "\n",
    "### 3.指定可见的gpu\n",
    "\n",
    "在命令行执行 export CUDA_VISIBLE_DEVICES = \"8,9,10,11,12,13,14,15\"（你所用的gpu编号）\n",
    "\n",
    "或者直接在~/.bashrc中加入（如果你和别人使用不同的登陆账号的话）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# python设置系统变量的方法\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"8,9,10,11,12,13,14,15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  44.   56.]\n",
      " [  98.  128.]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print sess.run(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![图六](https://raw.githubusercontent.com/applenob/deep_learning_note/master/res/6.jpg)\n",
    "\n",
    "结果显示只有后面8个GPU显存被占用。\n",
    "\n",
    "** 注意，在代码中指定设备时，重新从0开始计，而不是从8开始。**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}